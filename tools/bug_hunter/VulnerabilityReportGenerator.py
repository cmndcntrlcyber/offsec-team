import os
import json
import time
import logging
import hashlib
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple, Union, Any
from pydantic import BaseModel, Field

class VulnerabilityReportGenerator:
    """
    A tool for generating comprehensive vulnerability reports.
    Provides capabilities for creating detailed security reports, executive summaries, and remediation guides.
    """
    
    def __init__(self):
        self.report_templates = {
            "executive": self._get_executive_template(),
            "technical": self._get_technical_template(),
            "compliance": self._get_compliance_template(),
            "remediation": self._get_remediation_template()
        }
        
        self.report_formats = {
            "html": self._generate_html_report,
            "pdf": self._generate_pdf_report,
            "json": self._generate_json_report,
            "csv": self._generate_csv_report,
            "markdown": self._generate_markdown_report
        }
        
        self.severity_colors = {
            "critical": "#dc3545",  # Red
            "high": "#fd7e14",      # Orange
            "medium": "#ffc107",    # Yellow
            "low": "#28a745",       # Green
            "info": "#17a2b8"       # Blue
        }
        
        self.report_history = {}
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger("VulnerabilityReportGenerator")
    
    def generate_comprehensive_report(self, vulnerability_data: Dict[str, Any] = Field(..., description="Vulnerability data to include in report"), 
                                    report_config: Dict[str, Any] = Field({}, description="Report configuration options")) -> Dict[str, Any]:
        """
        Create detailed vulnerability reports from scan results.
        
        Args:
            vulnerability_data: Dictionary containing vulnerability scan results
                Required keys:
                - vulnerabilities: List of vulnerability dictionaries
                - scan_metadata: Metadata about the scan (target, timestamp, etc.)
                Optional keys:
                - remediation_notes: Additional remediation guidance
                - compliance_mapping: Mapping to compliance frameworks
            report_config: Configuration for report generation
                Optional keys:
                - report_type: Type of report (executive, technical, compliance, remediation)
                - format: Output format (html, pdf, json, csv, markdown)
                - include_sections: List of sections to include
                - branding: Company branding information
                - custom_fields: Additional custom fields to include
            
        Returns:
            Dictionary containing the generated report and metadata
        """
        # Validate vulnerability data
        if not vulnerability_data:
            return {
                "success": False,
                "error": "Vulnerability data is required"
            }
        
        if "vulnerabilities" not in vulnerability_data:
            return {
                "success": False,
                "error": "Vulnerability data must contain 'vulnerabilities' key"
            }
        
        if "scan_metadata" not in vulnerability_data:
            return {
                "success": False,
                "error": "Vulnerability data must contain 'scan_metadata' key"
            }
        
        # Set default configuration
        report_type = report_config.get("report_type", "technical")
        output_format = report_config.get("format", "html")
        include_sections = report_config.get("include_sections", ["all"])
        
        # Validate report type and format
        if report_type not in self.report_templates:
            return {
                "success": False,
                "error": f"Invalid report type '{report_type}'. Available types: {', '.join(self.report_templates.keys())}"
            }
        
        if output_format not in self.report_formats:
            return {
                "success": False,
                "error": f"Invalid format '{output_format}'. Available formats: {', '.join(self.report_formats.keys())}"
            }
        
        try:
            self.logger.info(f"Generating {report_type} report in {output_format} format")
            
            # Generate report ID
            report_id = f"vuln-report-{int(time.time())}"
            
            # Process vulnerability data
            processed_data = self._process_vulnerability_data(vulnerability_data)
            
            # Generate report content based on template
            template = self.report_templates[report_type]
            report_content = self._populate_template(template, processed_data, report_config, include_sections)
            
            # Format report based on requested format
            formatter = self.report_formats[output_format]
            formatted_report = formatter(report_content, processed_data, report_config)
            
            # Generate report metadata
            report_metadata = {
                "report_id": report_id,
                "report_type": report_type,
                "format": output_format,
                "generated_at": datetime.now(timezone.utc).isoformat(),
                "target": processed_data["scan_metadata"].get("target", "Unknown"),
                "total_vulnerabilities": processed_data["summary"]["total_vulnerabilities"],
                "severity_breakdown": processed_data["summary"]["severity_counts"],
                "report_hash": hashlib.sha256(str(formatted_report).encode()).hexdigest()[:16]
            }
            
            # Store report in history
            self.report_history[report_id] = {
                "metadata": report_metadata,
                "config": report_config,
                "vulnerability_data": vulnerability_data,
                "processed_data": processed_data,
                "content": formatted_report,
                "timestamp": time.time()
            }
            
            return {
                "success": True,
                "report_id": report_id,
                "metadata": report_metadata,
                "content": formatted_report,
                "recommendations": self._generate_high_level_recommendations(processed_data)
            }
            
        except Exception as e:
            self.logger.error(f"Error generating vulnerability report: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def create_executive_summary(self, vulnerability_data: Dict[str, Any] = Field(..., description="Vulnerability data for summary"), 
                               summary_config: Dict[str, Any] = Field({}, description="Summary configuration")) -> Dict[str, Any]:
        """
        Generate executive-level summaries for stakeholders.
        
        Args:
            vulnerability_data: Dictionary containing vulnerability scan results
            summary_config: Configuration for summary generation
                Optional keys:
                - focus_areas: List of areas to focus on (risk, compliance, business_impact)
                - metrics_priority: Priority order for metrics display
                - executive_audience: Target audience level (c-suite, director, manager)
            
        Returns:
            Dictionary containing the executive summary
        """
        try:
            self.logger.info("Generating executive summary")
            
            # Process vulnerability data
            processed_data = self._process_vulnerability_data(vulnerability_data)
            
            # Generate executive summary content
            summary_content = self._generate_executive_summary_content(processed_data, summary_config)
            
            # Generate summary ID
            summary_id = f"exec-summary-{int(time.time())}"
            
            # Store summary
            self.report_history[summary_id] = {
                "type": "executive_summary",
                "content": summary_content,
                "config": summary_config,
                "processed_data": processed_data,
                "timestamp": time.time()
            }
            
            return {
                "success": True,
                "summary_id": summary_id,
                "content": summary_content,
                "key_metrics": processed_data["summary"],
                "top_risks": self._identify_top_risks(processed_data),
                "business_impact": self._assess_business_impact(processed_data, summary_config)
            }
            
        except Exception as e:
            self.logger.error(f"Error generating executive summary: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def export_report_data(self, report_id: str = Field(..., description="ID of the report to export"), 
                         export_format: str = Field("json", description="Export format")) -> Dict[str, Any]:
        """
        Export report data in various formats for integration.
        
        Args:
            report_id: ID of the report to export
            export_format: Format to export in (json, xml, csv, sarif)
            
        Returns:
            Dictionary containing exported data
        """
        # Validate parameters
        if not report_id:
            return {
                "success": False,
                "error": "Report ID is required"
            }
        
        if report_id not in self.report_history:
            return {
                "success": False,
                "error": f"Report ID '{report_id}' not found"
            }
        
        if export_format not in ["json", "xml", "csv", "sarif"]:
            return {
                "success": False,
                "error": f"Invalid export format '{export_format}'. Supported formats: json, xml, csv, sarif"
            }
        
        try:
            self.logger.info(f"Exporting report {report_id} in {export_format} format")
            
            # Get report data
            report = self.report_history[report_id]
            processed_data = report.get("processed_data", {})
            
            # Export based on format
            if export_format == "json":
                exported_data = self._export_json(processed_data)
            elif export_format == "xml":
                exported_data = self._export_xml(processed_data)
            elif export_format == "csv":
                exported_data = self._export_csv(processed_data)
            elif export_format == "sarif":
                exported_data = self._export_sarif(processed_data)
            else:
                return {
                    "success": False,
                    "error": f"Export format '{export_format}' not implemented"
                }
            
            return {
                "success": True,
                "export_format": export_format,
                "exported_data": exported_data,
                "export_timestamp": datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error exporting report data: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _process_vulnerability_data(self, vulnerability_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process and enrich vulnerability data for reporting"""
        vulnerabilities = vulnerability_data.get("vulnerabilities", [])
        scan_metadata = vulnerability_data.get("scan_metadata", {})
        
        # Calculate summary statistics
        severity_counts = {
            "critical": 0,
            "high": 0,
            "medium": 0,
            "low": 0,
            "info": 0
        }
        
        vulnerability_types = {}
        affected_components = set()
        
        for vuln in vulnerabilities:
            # Count by severity
            severity = vuln.get("severity", "unknown").lower()
            if severity in severity_counts:
                severity_counts[severity] += 1
            
            # Count by vulnerability type
            vuln_type = vuln.get("type", "Unknown")
            vulnerability_types[vuln_type] = vulnerability_types.get(vuln_type, 0) + 1
            
            # Track affected components
            url = vuln.get("url", "")
            if url:
                # Extract domain/component from URL
                try:
                    from urllib.parse import urlparse
                    parsed = urlparse(url)
                    component = f"{parsed.netloc}{parsed.path.split('/')[1] if parsed.path != '/' else ''}"
                    affected_components.add(component)
                except:
                    affected_components.add(url)
        
        # Calculate risk scores
        risk_score = self._calculate_risk_score(severity_counts)
        
        # Generate trends (simulated)
        trends = self._generate_trend_analysis(severity_counts)
        
        # Process remediation data
        remediation_summary = self._process_remediation_data(vulnerabilities)
        
        return {
            "vulnerabilities": vulnerabilities,
            "scan_metadata": scan_metadata,
            "summary": {
                "total_vulnerabilities": len(vulnerabilities),
                "severity_counts": severity_counts,
                "vulnerability_types": vulnerability_types,
                "affected_components": list(affected_components),
                "risk_score": risk_score,
                "scan_coverage": scan_metadata.get("scan_coverage", "Unknown")
            },
            "trends": trends,
            "remediation": remediation_summary
        }
    
    def _calculate_risk_score(self, severity_counts: Dict[str, int]) -> Dict[str, Any]:
        """Calculate overall risk score based on vulnerabilities"""
        # Weight severities differently
        weights = {
            "critical": 10,
            "high": 7,
            "medium": 4,
            "low": 1,
            "info": 0.1
        }
        
        total_score = 0
        total_vulns = 0
        
        for severity, count in severity_counts.items():
            if severity in weights:
                total_score += weights[severity] * count
                total_vulns += count
        
        if total_vulns == 0:
            return {
                "score": 0,
                "level": "None",
                "description": "No vulnerabilities detected"
            }
        
        # Normalize score to 0-100 range
        max_possible = weights["critical"] * total_vulns
        normalized_score = (total_score / max_possible) * 100 if max_possible > 0 else 0
        
        # Determine risk level
        if normalized_score >= 80:
            level = "Critical"
            description = "Immediate action required - critical vulnerabilities present"
        elif normalized_score >= 60:
            level = "High"
            description = "High risk - prompt remediation recommended"
        elif normalized_score >= 40:
            level = "Medium"
            description = "Moderate risk - remediation should be planned"
        elif normalized_score >= 20:
            level = "Low"
            description = "Low risk - monitor and remediate when convenient"
        else:
            level = "Minimal"
            description = "Minimal risk - mostly informational findings"
        
        return {
            "score": round(normalized_score, 1),
            "level": level,
            "description": description
        }
    
    def _generate_trend_analysis(self, severity_counts: Dict[str, int]) -> Dict[str, Any]:
        """Generate trend analysis (simulated for demonstration)"""
        # In a real implementation, this would compare against historical data
        import random
        
        trends = {}
        for severity, count in severity_counts.items():
            # Simulate trend data
            previous_count = max(0, count + random.randint(-3, 3))
            
            if count > previous_count:
                trend = "increasing"
                change = ((count - previous_count) / max(previous_count, 1)) * 100
            elif count < previous_count:
                trend = "decreasing"
                change = ((previous_count - count) / max(previous_count, 1)) * 100
            else:
                trend = "stable"
                change = 0
            
            trends[severity] = {
                "current": count,
                "previous": previous_count,
                "trend": trend,
                "change_percent": round(change, 1)
            }
        
        return trends
    
    def _process_remediation_data(self, vulnerabilities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Process remediation information from vulnerabilities"""
        remediation_efforts = {
            "immediate": [],  # Critical/High severity
            "short_term": [], # Medium severity
            "long_term": []   # Low/Info severity
        }
        
        effort_estimates = {
            "immediate": 0,
            "short_term": 0,
            "long_term": 0
        }
        
        for vuln in vulnerabilities:
            severity = vuln.get("severity", "unknown").lower()
            
            # Categorize by urgency
            if severity in ["critical", "high"]:
                category = "immediate"
                effort = 4  # Hours
            elif severity == "medium":
                category = "short_term"
                effort = 2  # Hours
            else:
                category = "long_term"
                effort = 1  # Hours
            
            remediation_efforts[category].append({
                "vulnerability": vuln.get("type", "Unknown"),
                "url": vuln.get("url", ""),
                "recommendation": vuln.get("remediation", ""),
                "estimated_effort": effort
            })
            
            effort_estimates[category] += effort
        
        return {
            "by_urgency": remediation_efforts,
            "effort_estimates": effort_estimates,
            "total_effort": sum(effort_estimates.values()),
            "priority_order": self._generate_priority_order(vulnerabilities)
        }
    
    def _generate_priority_order(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Generate priority-ordered list of vulnerabilities"""
        # Sort by severity and then by exploitability/impact
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}
        
        prioritized = sorted(vulnerabilities, key=lambda v: (
            severity_order.get(v.get("severity", "unknown").lower(), 5),
            -v.get("cvss_score", 0)  # Higher CVSS = higher priority
        ))
        
        # Return top 10 priorities
        return prioritized[:10]
    
    def _populate_template(self, template: str, processed_data: Dict[str, Any], config: Dict[str, Any], include_sections: List[str]) -> Dict[str, Any]:
        """Populate report template with processed data"""
        # This would contain the main report structure
        report_content = {
            "header": self._generate_header(processed_data, config),
            "executive_summary": self._generate_executive_section(processed_data, config),
            "vulnerability_details": self._generate_vulnerability_section(processed_data, config),
            "risk_assessment": self._generate_risk_section(processed_data, config),
            "remediation_plan": self._generate_remediation_section(processed_data, config),
            "appendices": self._generate_appendices(processed_data, config)
        }
        
        # Filter sections based on include_sections
        if "all" not in include_sections:
            filtered_content = {}
            for section in include_sections:
                if section in report_content:
                    filtered_content[section] = report_content[section]
            report_content = filtered_content
        
        return report_content
    
    def _generate_header(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate report header section"""
        scan_metadata = processed_data.get("scan_metadata", {})
        branding = config.get("branding", {})
        
        return {
            "title": "Vulnerability Assessment Report",
            "subtitle": f"Security Analysis for {scan_metadata.get('target', 'Target Application')}",
            "generated_date": datetime.now(timezone.utc).strftime("%B %d, %Y"),
            "company_name": branding.get("company_name", "Security Team"),
            "company_logo": branding.get("logo_url", ""),
            "report_version": "1.0",
            "classification": config.get("classification", "Confidential")
        }
    
    def _generate_executive_section(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate executive summary section"""
        summary = processed_data.get("summary", {})
        risk_score = summary.get("risk_score", {})
        
        return {
            "overview": f"This report presents the findings from a comprehensive security assessment of {processed_data['scan_metadata'].get('target', 'the target application')}.",
            "key_findings": [
                f"Total of {summary.get('total_vulnerabilities', 0)} vulnerabilities identified",
                f"Risk level assessed as {risk_score.get('level', 'Unknown')}",
                f"{summary.get('severity_counts', {}).get('critical', 0)} critical vulnerabilities require immediate attention",
                f"Estimated remediation effort: {processed_data.get('remediation', {}).get('total_effort', 0)} hours"
            ],
            "risk_summary": risk_score,
            "recommendations": self._generate_high_level_recommendations(processed_data)
        }
    
    def _generate_vulnerability_section(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate detailed vulnerability section"""
        vulnerabilities = processed_data.get("vulnerabilities", [])
        summary = processed_data.get("summary", {})
        
        # Group vulnerabilities by severity
        by_severity = {}
        for vuln in vulnerabilities:
            severity = vuln.get("severity", "unknown").lower()
            if severity not in by_severity:
                by_severity[severity] = []
            by_severity[severity].append(vuln)
        
        return {
            "total_count": len(vulnerabilities),
            "severity_breakdown": summary.get("severity_counts", {}),
            "by_severity": by_severity,
            "by_type": summary.get("vulnerability_types", {}),
            "affected_components": summary.get("affected_components", []),
            "detailed_findings": vulnerabilities[:50]  # Limit for report readability
        }
    
    def _generate_risk_section(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate risk assessment section"""
        return {
            "overall_risk": processed_data["summary"]["risk_score"],
            "risk_factors": self._identify_risk_factors(processed_data),
            "business_impact": self._assess_business_impact(processed_data, config),
            "threat_landscape": self._generate_threat_context(processed_data)
        }
    
    def _generate_remediation_section(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate remediation plan section"""
        return processed_data.get("remediation", {})
    
    def _generate_appendices(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate appendices section"""
        return {
            "scan_methodology": self._get_scan_methodology(processed_data),
            "vulnerability_definitions": self._get_vulnerability_definitions(),
            "compliance_mapping": self._generate_compliance_mapping(processed_data, config),
            "technical_details": self._get_technical_details(processed_data)
        }
    
    def _generate_high_level_recommendations(self, processed_data: Dict[str, Any]) -> List[str]:
        """Generate high-level recommendations"""
        recommendations = []
        severity_counts = processed_data["summary"]["severity_counts"]
        
        if severity_counts.get("critical", 0) > 0:
            recommendations.append("Address critical vulnerabilities immediately - these pose immediate risk to the organization")
        
        if severity_counts.get("high", 0) > 0:
            recommendations.append("Prioritize high severity vulnerabilities for remediation within the next sprint")
        
        if severity_counts.get("medium", 0) > 5:
            recommendations.append("Develop a systematic approach to address the significant number of medium severity findings")
        
        if processed_data["summary"]["total_vulnerabilities"] > 20:
            recommendations.append("Consider implementing automated security testing in the CI/CD pipeline")
        
        recommendations.append("Establish regular security assessment schedule to prevent vulnerability accumulation")
        
        return recommendations
    
    def _identify_top_risks(self, processed_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify top risks for executive summary"""
        vulnerabilities = processed_data.get("vulnerabilities", [])
        
        # Sort by severity and CVSS score
        top_risks = sorted(vulnerabilities, key=lambda v: (
            {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}.get(v.get("severity", "unknown").lower(), 5),
            -v.get("cvss_score", 0)
        ))[:5]
        
        return [
            {
                "title": risk.get("type", "Unknown Vulnerability"),
                "severity": risk.get("severity", "Unknown"),
                "location": risk.get("url", "Unknown Location"),
                "impact": risk.get("impact", "Impact assessment needed"),
                "cvss_score": risk.get("cvss_score", 0)
            }
            for risk in top_risks
        ]
    
    def _assess_business_impact(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Assess business impact of vulnerabilities"""
        severity_counts = processed_data["summary"]["severity_counts"]
        risk_score = processed_data["summary"]["risk_score"]
        
        # Simulate business impact assessment
        impact_areas = {
            "data_confidentiality": "High" if severity_counts.get("critical", 0) > 0 else "Medium",
            "service_availability": "High" if severity_counts.get("high", 0) > 3 else "Low",
            "regulatory_compliance": "Medium" if severity_counts.get("medium", 0) > 5 else "Low",
            "reputation_risk": risk_score.get("level", "Low")
        }
        
        return {
            "impact_areas": impact_areas,
            "estimated_cost": self._estimate_breach_cost(severity_counts),
            "compliance_risk": self._assess_compliance_risk(processed_data, config)
        }
    
    def _estimate_breach_cost(self, severity_counts: Dict[str, int]) -> Dict[str, Any]:
        """Estimate potential breach cost (simplified model)"""
        # Simplified cost estimation
        base_cost = 50000  # Base cost for any security incident
        
        cost_multipliers = {
            "critical": 100000,
            "high": 25000,
            "medium": 5000,
            "low": 1000,
            "info": 0
        }
        
        estimated_cost = base_cost
        for severity, count in severity_counts.items():
            if severity in cost_multipliers:
                estimated_cost += cost_multipliers[severity] * count
        
        return {
            "estimated_range": f"${estimated_cost//2:,} - ${estimated_cost:,}",
            "factors": "Based on industry averages for data breach costs and remediation efforts"
        }
    
    def _assess_compliance_risk(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Assess compliance risk level"""
        severity_counts = processed_data["summary"]["severity_counts"]
        
        if severity_counts.get("critical", 0) > 0 or severity_counts.get("high", 0) > 5:
            return "High - May result in compliance violations"
        elif severity_counts.get("medium", 0) > 10:
            return "Medium - Should be addressed to maintain compliance"
        else:
            return "Low - Minimal compliance impact expected"
    
    def _identify_risk_factors(self, processed_data: Dict[str, Any]) -> List[str]:
        """Identify key risk factors"""
        factors = []
        severity_counts = processed_data["summary"]["severity_counts"]
        vuln_types = processed_data["summary"]["vulnerability_types"]
        
        if severity_counts.get("critical", 0) > 0:
            factors.append("Presence of critical vulnerabilities requiring immediate attention")
        
        if "SQL Injection" in vuln_types:
            factors.append("SQL injection vulnerabilities pose data breach risk")
        
        if "Cross-site Scripting (XSS)" in vuln_types:
            factors.append("XSS vulnerabilities may lead to account compromise")
        
        if len(processed_data["summary"]["affected_components"]) > 5:
            factors.append("Multiple components affected, suggesting systemic issues")
        
        return factors
    
    def _generate_threat_context(self, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate threat landscape context"""
        return {
            "current_threat_level": "Elevated",
            "relevant_threats": [
                "Web application attacks targeting common vulnerabilities",
                "Data exfiltration attempts through SQL injection",
                "Client-side attacks via cross-site scripting"
            ],
            "industry_context": "Web applications continue to be primary attack vectors for cybercriminals"
        }
    
    def _get_scan_methodology(self, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """Get scan methodology information"""
        return {
            "approach": "Comprehensive automated and manual security testing",
            "tools_used": processed_data["scan_metadata"].get("scanner", "Multiple security tools"),
            "coverage": processed_data["scan_metadata"].get("scan_coverage", "Full application scope"),
            "limitations": [
                "Automated scanning may not detect all logic flaws",
                "Manual testing was limited to publicly accessible endpoints",
                "Source code review was not performed"
            ]
        }
    
    def _get_vulnerability_definitions(self) -> Dict[str, str]:
        """Get vulnerability definitions for appendix"""
        return {
            "Critical": "Vulnerabilities that can be exploited remotely with minimal effort and result in complete system compromise",
            "High": "Vulnerabilities that can be exploited to gain unauthorized access or significantly impact system functionality",
            "Medium": "Vulnerabilities that require specific conditions to exploit but could result in information disclosure or limited access",
            "Low": "Vulnerabilities that have minimal impact or require significant effort/access to exploit",
            "Informational": "Security findings that don't pose immediate risk but indicate security misconfigurations"
        }
    
    def _generate_compliance_mapping(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, List[str]]:
        """Generate compliance framework mapping"""
        # Map common vulnerability types to compliance requirements
        compliance_mapping = {
            "PCI DSS": [],
            "OWASP Top 10": [],
            "NIST": [],
            "ISO 27001": []
        }
        
        vulnerability_types = processed_data["summary"]["vulnerability_types"]
        
        # Map to PCI DSS requirements
        if "SQL Injection" in vulnerability_types:
            compliance_mapping["PCI DSS"].append("Requirement 6.5.1 - Injection flaws")
        if "Cross-site Scripting (XSS)" in vulnerability_types:
            compliance_mapping["PCI DSS"].append("Requirement 6.5.7 - Cross-site scripting (XSS)")
        if "Insecure Authentication" in vulnerability_types:
            compliance_mapping["PCI DSS"].append("Requirement 8 - Identify and authenticate access")
        
        # Map to OWASP Top 10
        owasp_mapping = {
            "SQL Injection": "A03:2021 – Injection",
            "Cross-site Scripting (XSS)": "A03:2021 – Injection",
            "Cross-site Request Forgery (CSRF)": "A01:2021 – Broken Access Control",
            "Insecure Direct Object References": "A01:2021 – Broken Access Control",
            "Server-side Request Forgery (SSRF)": "A10:2021 – Server-Side Request Forgery",
            "XML External Entity (XXE)": "A05:2021 – Security Misconfiguration"
        }
        
        for vuln_type in vulnerability_types:
            if vuln_type in owasp_mapping:
                compliance_mapping["OWASP Top 10"].append(owasp_mapping[vuln_type])
        
        return compliance_mapping
    
    def _get_technical_details(self, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """Get technical details for appendix"""
        return {
            "scan_parameters": processed_data["scan_metadata"],
            "vulnerability_statistics": processed_data["summary"],
            "raw_findings_count": len(processed_data["vulnerabilities"])
        }
    
    def _generate_executive_summary_content(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate executive summary content"""
        focus_areas = config.get("focus_areas", ["risk", "compliance", "business_impact"])
        
        content = {
            "situation_overview": self._generate_situation_overview(processed_data),
            "key_metrics": processed_data["summary"],
            "immediate_actions": self._identify_immediate_actions(processed_data),
            "strategic_recommendations": self._generate_strategic_recommendations(processed_data)
        }
        
        # Add focus area specific content
        if "risk" in focus_areas:
            content["risk_analysis"] = self._generate_risk_analysis(processed_data)
        
        if "compliance" in focus_areas:
            content["compliance_status"] = self._generate_compliance_status(processed_data, config)
        
        if "business_impact" in focus_areas:
            content["business_impact"] = self._assess_business_impact(processed_data, config)
        
        return content
    
    def _generate_situation_overview(self, processed_data: Dict[str, Any]) -> str:
        """Generate situation overview for executives"""
        total_vulns = processed_data["summary"]["total_vulnerabilities"]
        risk_level = processed_data["summary"]["risk_score"]["level"]
        target = processed_data["scan_metadata"].get("target", "the application")
        
        if total_vulns == 0:
            return f"Security assessment of {target} completed with no significant vulnerabilities identified."
        elif risk_level in ["Critical", "High"]:
            return f"Security assessment of {target} revealed {total_vulns} vulnerabilities with {risk_level.lower()} risk level requiring immediate attention."
        else:
            return f"Security assessment of {target} identified {total_vulns} vulnerabilities with {risk_level.lower()} overall risk level."
    
    def _identify_immediate_actions(self, processed_data: Dict[str, Any]) -> List[str]:
        """Identify immediate actions needed"""
        actions = []
        severity_counts = processed_data["summary"]["severity_counts"]
        
        if severity_counts.get("critical", 0) > 0:
            actions.append(f"Patch {severity_counts['critical']} critical vulnerabilities within 24-48 hours")
        
        if severity_counts.get("high", 0) > 0:
            actions.append(f"Address {severity_counts['high']} high severity vulnerabilities within one week")
        
        if len(processed_data["summary"]["affected_components"]) > 3:
            actions.append("Implement comprehensive security testing across all application components")
        
        return actions
    
    def _generate_strategic_recommendations(self, processed_data: Dict[str, Any]) -> List[str]:
        """Generate strategic recommendations"""
        return [
            "Integrate security testing into the development lifecycle",
            "Establish regular penetration testing schedule",
            "Implement security awareness training for development teams",
            "Consider bug bounty program for ongoing security validation"
        ]
    
    def _generate_risk_analysis(self, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate detailed risk analysis"""
        return {
            "current_posture": processed_data["summary"]["risk_score"],
            "trend_analysis": processed_data["trends"],
            "risk_factors": self._identify_risk_factors(processed_data)
        }
    
    def _generate_compliance_status(self, processed_data: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
        """Generate compliance status overview"""
        return {
            "frameworks": self._generate_compliance_mapping(processed_data, config),
            "compliance_risk": self._assess_compliance_risk(processed_data, config),
            "recommendations": [
                "Ensure all critical and high severity vulnerabilities are addressed for compliance",
                "Document remediation efforts for audit purposes",
                "Implement continuous compliance monitoring"
            ]
        }
    
    # Report format generators
    def _generate_html_report(self, content: Dict[str, Any], processed_data: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Generate HTML format report"""
        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>{content['header']['title']}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        .header {{ background-color: #f8f9fa; padding: 20px; border-radius: 5px; }}
        .severity-critical {{ color: {self.severity_colors['critical']}; }}
        .severity-high {{ color: {self.severity_colors['high']}; }}
        .severity-medium {{ color: {self.severity_colors['medium']}; }}
        .severity-low {{ color: {self.severity_colors['low']}; }}
        .severity-info {{ color: {self.severity_colors['info']}; }}
        .vulnerability {{ border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>{content['header']['title']}</h1>
        <h2>{content['header']['subtitle']}</h2>
        <p>Generated: {content['header']['generated_date']}</p>
        <p>Classification: {content['header']['classification']}</p>
    </div>
    
    <h2>Executive Summary</h2>
    <p>{content['executive_summary']['overview']}</p>
    <ul>
        {''.join(f"<li>{finding}</li>" for finding in content['executive_summary']['key_findings'])}
    </ul>
    
    <h2>Vulnerability Breakdown</h2>
    <table>
        <tr><th>Severity</th><th>Count</th></tr>
        {''.join(f"<tr><td class='severity-{sev}'>{sev.title()}</td><td>{count}</td></tr>" for sev, count in content['vulnerability_details']['severity_breakdown'].items())}
    </table>
    
    <h2>Detailed Findings</h2>
    {''.join(f'''
    <div class="vulnerability">
        <h3 class="severity-{vuln.get('severity', 'unknown')}">{vuln.get('type', 'Unknown')} ({vuln.get('severity', 'Unknown').title()})</h3>
        <p><strong>Location:</strong> {vuln.get('url', 'Unknown')}</p>
        <p><strong>Description:</strong> {vuln.get('description', 'No description available')}</p>
        <p><strong>Recommendation:</strong> {vuln.get('remediation', 'No remediation provided')}</p>
    </div>
    ''' for vuln in content['vulnerability_details']['detailed_findings'][:10])}
    
</body>
</html>"""
        return html
    
    def _generate_pdf_report(self, content: Dict[str, Any], processed_data: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Generate PDF format report (placeholder)"""
        # In a real implementation, this would use a PDF generation library
        return "PDF generation would require additional dependencies like ReportLab or WeasyPrint"
    
    def _generate_json_report(self, content: Dict[str, Any], processed_data: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Generate JSON format report"""
        return json.dumps(content, indent=2, default=str)
    
    def _generate_csv_report(self, content: Dict[str, Any], processed_data: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Generate CSV format report"""
        vulnerabilities = content['vulnerability_details']['detailed_findings']
        
        if not vulnerabilities:
            return "No vulnerabilities to export"
        
        # CSV headers
        headers = ["Type", "Severity", "URL", "Description", "Recommendation", "CVSS Score"]
        
        # Generate CSV content
        csv_lines = [",".join([f'"{h}"' for h in headers])]
        
        for vuln in vulnerabilities:
            row = [
                vuln.get("type", ""),
                vuln.get("severity", ""),
                vuln.get("url", ""),
                vuln.get("description", "").replace('"', '""'),
                vuln.get("remediation", "").replace('"', '""'),
                str(vuln.get("cvss_score", ""))
            ]
            csv_lines.append(",".join([f'"{cell}"' for cell in row]))
        
        return "\n".join(csv_lines)
    
    def _generate_markdown_report(self, content: Dict[str, Any], processed_data: Dict[str, Any], config: Dict[str, Any]) -> str:
        """Generate Markdown format report"""
        md = f"""# {content['header']['title']}

## {content['header']['subtitle']}

**Generated:** {content['header']['generated_date']}  
**Classification:** {content['header']['classification']}

## Executive Summary

{content['executive_summary']['overview']}

### Key Findings
"""
        
        for finding in content['executive_summary']['key_findings']:
            md += f"- {finding}\n"
        
        md += "\n## Vulnerability Breakdown\n\n"
        md += "| Severity | Count |\n|----------|-------|\n"
        
        for severity, count in content['vulnerability_details']['severity_breakdown'].items():
            md += f"| {severity.title()} | {count} |\n"
        
        md += "\n## Detailed Findings\n\n"
        
        for vuln in content['vulnerability_details']['detailed_findings'][:10]:
            md += f"""### {vuln.get('type', 'Unknown')} ({vuln.get('severity', 'Unknown').title()})

**Location:** {vuln.get('url', 'Unknown')}  
**Description:** {vuln.get('description', 'No description available')}  
**Recommendation:** {vuln.get('remediation', 'No remediation provided')}

---

"""
        
        return md
    
    def _export_json(self, processed_data: Dict[str, Any]) -> str:
        """Export data as JSON"""
        return json.dumps(processed_data, indent=2, default=str)
    
    def _export_xml(self, processed_data: Dict[str, Any]) -> str:
        """Export data as XML"""
        # Basic XML generation (would use proper XML library in production)
        xml = '<?xml version="1.0" encoding="UTF-8"?>\n<vulnerability_report>\n'
        
        # Add metadata
        xml += f"  <scan_metadata>\n"
        for key, value in processed_data["scan_metadata"].items():
            xml += f"    <{key}>{value}</{key}>\n"
        xml += f"  </scan_metadata>\n"
        
        # Add vulnerabilities
        xml += "  <vulnerabilities>\n"
        for vuln in processed_data["vulnerabilities"]:
            xml += "    <vulnerability>\n"
            for key, value in vuln.items():
                # Escape XML special characters
                value_str = str(value).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                xml += f"      <{key}>{value_str}</{key}>\n"
            xml += "    </vulnerability>\n"
        xml += "  </vulnerabilities>\n"
        
        xml += "</vulnerability_report>"
        return xml
    
    def _export_csv(self, processed_data: Dict[str, Any]) -> str:
        """Export data as CSV"""
        return self._generate_csv_report({}, processed_data, {})
    
    def _export_sarif(self, processed_data: Dict[str, Any]) -> str:
        """Export data as SARIF format"""
        sarif = {
            "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
            "version": "2.1.0",
            "runs": [
                {
                    "tool": {
                        "driver": {
                            "name": "VulnerabilityReportGenerator",
                            "informationUri": "https://example.com/tools/vulnerability-report-generator",
                            "rules": []
                        }
                    },
                    "results": []
                }
            ]
        }
        
        # Create rules and results
        rule_indices = {}
        
        for vuln in processed_data["vulnerabilities"]:
            vuln_type = vuln.get("type", "Unknown")
            cwe = vuln.get("cwe", "Unknown")
            
            # Create rule if it doesn't exist
            rule_id = cwe.replace("-", "") if cwe != "Unknown" else f"VULN-{len(rule_indices)}"
            if rule_id not in rule_indices:
                rule = {
                    "id": rule_id,
                    "name": vuln_type,
                    "shortDescription": {
                        "text": vuln_type
                    },
                    "fullDescription": {
                        "text": vuln.get("description", "")
                    },
                    "defaultConfiguration": {
                        "level": self._convert_severity_to_sarif_level(vuln.get("severity", ""))
                    }
                }
                
                rule_indices[rule_id] = len(sarif["runs"][0]["tool"]["driver"]["rules"])
                sarif["runs"][0]["tool"]["driver"]["rules"].append(rule)
            
            # Create result
            result = {
                "ruleId": rule_id,
                "ruleIndex": rule_indices[rule_id],
                "level": self._convert_severity_to_sarif_level(vuln.get("severity", "")),
                "message": {
                    "text": vuln.get("description", "")
                },
                "locations": [
                    {
                        "physicalLocation": {
                            "artifactLocation": {
                                "uri": vuln.get("url", "")
                            }
                        }
                    }
                ]
            }
            
            sarif["runs"][0]["results"].append(result)
        
        return json.dumps(sarif, indent=2)
    
    def _convert_severity_to_sarif_level(self, severity: str) -> str:
        """Convert vulnerability severity to SARIF level"""
        severity_map = {
            "critical": "error",
            "high": "error",
            "medium": "warning",
            "low": "note",
            "info": "note"
        }
        
        return severity_map.get(severity.lower(), "warning")
    
    # Template getters (simplified for demonstration)
    def _get_executive_template(self) -> str:
        return "executive_template"
    
    def _get_technical_template(self) -> str:
        return "technical_template"
    
    def _get_compliance_template(self) -> str:
        return "compliance_template"
    
    def _get_remediation_template(self) -> str:
        return "remediation_template"
