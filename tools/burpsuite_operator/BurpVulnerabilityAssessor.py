"""
BurpSuite Vulnerability Assessor for cybersecurity AI workflow integration.

This tool assesses and prioritizes BurpSuite findings with risk scoring,
validation, and remediation guidance.
"""

import logging
from datetime import datetime
from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field

from ..shared.data_models.security_models import Vulnerability, SeverityLevel, RiskAssessment
from .BurpSuiteAPIClient import BurpSuiteAPIClient


class BurpVulnerabilityAssessor:
    """
    Advanced vulnerability assessor for BurpSuite findings.
    Provides risk scoring, validation, and prioritization capabilities.
    """
    
    def __init__(self):
        """Initialize the BurpSuite vulnerability assessor."""
        self.api_client = BurpSuiteAPIClient()
        self.logger = logging.getLogger("BurpVulnerabilityAssessor")
    
    def calculate_vulnerability_risk(self, vulnerability: Dict[str, Any] = Field(..., description="Vulnerability data")) -> Dict[str, Any]:
        """
        Calculate comprehensive risk score for vulnerability.
        
        Args:
            vulnerability: Vulnerability information
            
        Returns:
            Risk assessment with scoring details
        """
        try:
            # Base severity scoring
            severity_scores = {"critical": 9.0, "high": 7.0, "medium": 5.0, "low": 3.0, "info": 1.0}
            base_score = severity_scores.get(vulnerability.get("severity", "info").lower(), 1.0)
            
            # Confidence factor (0.5 - 1.0)
            confidence_factors = {"high": 1.0, "medium": 0.8, "low": 0.6}
            confidence_factor = confidence_factors.get(vulnerability.get("confidence", "low"), 0.6)
            
            # Exploitability factors
            exploitability_score = self._assess_exploitability(vulnerability)
            
            # Impact factors  
            impact_score = self._assess_impact(vulnerability)
            
            # Calculate final risk score (0-10 scale)
            risk_score = min(10.0, (base_score * confidence_factor * exploitability_score * impact_score) / 10)
            
            # Determine risk level
            if risk_score >= 8.0:
                risk_level = "critical"
            elif risk_score >= 6.0:
                risk_level = "high"
            elif risk_score >= 4.0:
                risk_level = "medium"
            else:
                risk_level = "low"
            
            assessment = {
                "vulnerability_id": vulnerability.get("issue_id", ""),
                "risk_score": round(risk_score, 2),
                "risk_level": risk_level,
                "scoring_breakdown": {
                    "base_severity": base_score,
                    "confidence_factor": confidence_factor,
                    "exploitability": exploitability_score,
                    "impact": impact_score
                },
                "assessment_date": datetime.utcnow().isoformat()
            }
            
            return {"success": True, "assessment": assessment}
            
        except Exception as e:
            self.logger.error(f"Failed to calculate risk: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def prioritize_finding_remediation(self, findings: List[Dict[str, Any]] = Field(..., description="List of findings")) -> Dict[str, Any]:
        """
        Prioritize findings for remediation based on risk and business impact.
        
        Args:
            findings: List of vulnerability findings
            
        Returns:
            Prioritized remediation plan
        """
        try:
            prioritized_findings = []
            
            for finding in findings:
                # Calculate risk for each finding
                risk_result = self.calculate_vulnerability_risk(finding)
                if risk_result["success"]:
                    finding_with_risk = finding.copy()
                    finding_with_risk.update(risk_result["assessment"])
                    prioritized_findings.append(finding_with_risk)
            
            # Sort by risk score (highest first)
            prioritized_findings.sort(key=lambda x: x.get("risk_score", 0), reverse=True)
            
            # Group into priority tiers
            priority_tiers = {
                "immediate": [],    # Critical/High risk
                "short_term": [],   # Medium risk  
                "long_term": [],    # Low risk
                "informational": [] # Info findings
            }
            
            for finding in prioritized_findings:
                risk_level = finding.get("risk_level", "low")
                if risk_level in ["critical", "high"]:
                    priority_tiers["immediate"].append(finding)
                elif risk_level == "medium":
                    priority_tiers["short_term"].append(finding)
                elif risk_level == "low":
                    priority_tiers["long_term"].append(finding)
                else:
                    priority_tiers["informational"].append(finding)
            
            remediation_plan = {
                "total_findings": len(findings),
                "priority_summary": {
                    "immediate": len(priority_tiers["immediate"]),
                    "short_term": len(priority_tiers["short_term"]),
                    "long_term": len(priority_tiers["long_term"]),
                    "informational": len(priority_tiers["informational"])
                },
                "priority_tiers": priority_tiers,
                "recommendations": self._generate_remediation_recommendations(priority_tiers)
            }
            
            return {"success": True, "remediation_plan": remediation_plan}
            
        except Exception as e:
            self.logger.error(f"Failed to prioritize findings: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def validate_vulnerability_existence(self, vulnerability: Dict[str, Any] = Field(..., description="Vulnerability to validate")) -> Dict[str, Any]:
        """
        Validate that a vulnerability actually exists and is exploitable.
        
        Args:
            vulnerability: Vulnerability information
            
        Returns:
            Validation results
        """
        try:
            validation = {
                "vulnerability_id": vulnerability.get("issue_id", ""),
                "validated": False,
                "confidence_level": vulnerability.get("confidence", "low"),
                "validation_checks": [],
                "false_positive_indicators": [],
                "validation_date": datetime.utcnow().isoformat()
            }
            
            # Check 1: Evidence strength
            evidence = vulnerability.get("evidence", {})
            if evidence and len(str(evidence)) > 100:
                validation["validation_checks"].append("Strong evidence present")
            else:
                validation["false_positive_indicators"].append("Weak or missing evidence")
            
            # Check 2: Reproducibility indicators
            if vulnerability.get("confidence", "").lower() == "high":
                validation["validation_checks"].append("High confidence from scanner")
            
            # Check 3: Issue type reliability
            reliable_issue_types = ["sql injection", "cross-site scripting", "command injection"]
            issue_type = vulnerability.get("issue_type", "").lower()
            if any(reliable_type in issue_type for reliable_type in reliable_issue_types):
                validation["validation_checks"].append("Reliable vulnerability type")
            
            # Check 4: Parameter involvement
            if vulnerability.get("parameter"):
                validation["validation_checks"].append("Parameter-based vulnerability")
            
            # Determine overall validation
            checks_passed = len(validation["validation_checks"])
            false_positives = len(validation["false_positive_indicators"])
            
            if checks_passed >= 2 and false_positives == 0:
                validation["validated"] = True
                validation["validation_status"] = "confirmed"
            elif checks_passed > false_positives:
                validation["validated"] = True
                validation["validation_status"] = "probable"
            else:
                validation["validated"] = False
                validation["validation_status"] = "requires_manual_review"
            
            return {"success": True, "validation": validation}
            
        except Exception as e:
            self.logger.error(f"Failed to validate vulnerability: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def generate_executive_summary(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate executive summary of vulnerability assessment."""
        try:
            if not findings:
                return {"success": True, "summary": {"message": "No findings to summarize"}}
            
            # Calculate metrics
            total_findings = len(findings)
            severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
            risk_scores = []
            
            for finding in findings:
                severity = finding.get("severity", "info").lower()
                severity_counts[severity] += 1
                
                if "risk_score" in finding:
                    risk_scores.append(finding["risk_score"])
            
            avg_risk_score = sum(risk_scores) / len(risk_scores) if risk_scores else 0
            
            # Generate key insights
            key_insights = []
            if severity_counts["critical"] > 0:
                key_insights.append(f"{severity_counts['critical']} critical vulnerabilities require immediate attention")
            
            if severity_counts["high"] > 3:
                key_insights.append(f"High number of high-severity issues ({severity_counts['high']}) indicates systemic security problems")
            
            if avg_risk_score > 7:
                key_insights.append("Overall risk level is HIGH - immediate remediation recommended")
            elif avg_risk_score > 5:
                key_insights.append("Overall risk level is MEDIUM - remediation should be prioritized")
            
            summary = {
                "assessment_date": datetime.utcnow().isoformat(),
                "total_findings": total_findings,
                "severity_breakdown": severity_counts,
                "average_risk_score": round(avg_risk_score, 2),
                "key_insights": key_insights,
                "recommendations": {
                    "immediate_actions": severity_counts["critical"] + severity_counts["high"],
                    "short_term_actions": severity_counts["medium"],
                    "long_term_actions": severity_counts["low"] + severity_counts["info"]
                }
            }
            
            return {"success": True, "summary": summary}
            
        except Exception as e:
            self.logger.error(f"Failed to generate executive summary: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _assess_exploitability(self, vulnerability: Dict[str, Any]) -> float:
        """Assess exploitability factor (0.5 - 1.5)."""
        exploitability = 1.0
        
        issue_type = vulnerability.get("issue_type", "").lower()
        
        # High exploitability issues
        if any(term in issue_type for term in ["injection", "xss", "command"]):
            exploitability = 1.4
        # Medium exploitability  
        elif any(term in issue_type for term in ["csrf", "authentication", "authorization"]):
            exploitability = 1.2
        # Lower exploitability
        elif any(term in issue_type for term in ["disclosure", "configuration"]):
            exploitability = 0.8
        
        return exploitability
    
    def _assess_impact(self, vulnerability: Dict[str, Any]) -> float:
        """Assess impact factor (0.5 - 1.5)."""
        impact = 1.0
        
        issue_type = vulnerability.get("issue_type", "").lower()
        url = vulnerability.get("url", "").lower()
        
        # High impact areas
        if any(term in url for term in ["/admin", "/api", "/login", "/payment"]):
            impact = 1.3
        # Medium impact
        elif any(term in url for term in ["/user", "/account", "/profile"]):
            impact = 1.1
        
        # High impact vulnerability types
        if any(term in issue_type for term in ["injection", "authentication"]):
            impact *= 1.2
        
        return min(1.5, impact)
    
    def _generate_remediation_recommendations(self, priority_tiers: Dict[str, List]) -> List[str]:
        """Generate remediation recommendations based on findings."""
        recommendations = []
        
        if priority_tiers["immediate"]:
            recommendations.append("Address all critical and high-risk vulnerabilities within 24-48 hours")
            recommendations.append("Implement temporary mitigations if full fixes require more time")
        
        if priority_tiers["short_term"]:
            recommendations.append("Schedule medium-risk vulnerability fixes within 1-2 weeks")
            recommendations.append("Prioritize issues in critical business functions")
        
        if len(priority_tiers["immediate"]) > 5:
            recommendations.append("Consider emergency security review due to high number of critical issues")
        
        recommendations.append("Establish regular security scanning schedule to prevent future issues")
        
        return recommendations
